Feb 6, 2025 AI Applications in the Finance Industry Cont:

In modern finance, AI is used to detect fraud, assess risks, help leaders make investment decisions, and improve strategic planning. Despite its benefits, there are still unresolved issues and challenges, such as ethical concerns, bias, and data security.


Fraud Detection in Financial Institutions

Main Idea: Companies (like Swift) aim to build AI models that spot fraudulent transactions, including forged checks or duplicate checks, by analyzing anomalies in data and leveraging past feedback from real fraud cases.

Why It Matters: Early detection prevents financial losses and protects customers.

Example: If several checks with the same serial number suddenly appear under different accounts, AI can flag them before funds are withdrawn.

Use case Not yet solved by AI

1) Determining the projects risk and present value: Banks want to know if an investment will be profitable (e.g., earning more than 7% return) and if a product has genuine long-term value. Example: A bank considering funding a new fin tech startup would analyze market trends, estimated future cash flows, and the startup’s business model. Since AI hasn’t perfected this forecasting, human analysts still need to interpret the data.

2 Risk & Return: Predicting stock or market directions remains a challenge. Huge resources may be poured into AI models for forecasting, yet there’s no guarantee of accurate predictions.
Example: A hedge fund trains a complex model on years of stock data. Despite promising back tests, it struggles to predict sudden events like economic policy changes, underscoring the uncertainty of real-world outcomes.


3 Helping Leadership with financial decision: AI can support executives in deciding where to invest and how to structure capital—whether in new products or strategic building plans. Example: A bank’s leadership might use an AI tool to compare returns on different product lines, helping decide which line to expand or phase out.

	1. Where they have to do major investment(Which products to invest in)

	2. Capital Structure Choices – (Selecting Strategic Building Zones) 

4 Strategic Planning: By delegating financial planning tasks to AI, companies could reduce planning budgets and increase the variety or volume of products they develop. Example: A bank might let AI handle routine budget forecasts, freeing human teams to focus on creating new financial products—like specialized loans or investment services.

 	1. Lower Financial Planning Budget 

	2. Increased Number of Products (with AI's Help) 
	
	Key-idea: Decrease the financial budget and increase the amount of products(Decrease the planning budget as the financial planning is done by AI and they want to increase the number of products with AI’s help.)

5 Ethical AI Practices: Fairness and bias management are crucial. AI needs to progress in both areas to avoid discriminatory outcomes (e.g., unfair loan approvals).
Example: A credit-scoring AI that inadvertently favors one demographic could be retrained on more diverse data to ensure equal opportunity.

1) Fairness
 
2) Managing biases

AI has to make some progress in these two areas in order to be able to help in the financial industry.




6 Regulatory Ambiguities: Laws and ethics surrounding AI in finance are still forming. Clear frameworks are needed to guide AI usage and protect consumers.
Example: A bank may worry that an AI decision system violates privacy laws if it uses personal data in ways that regulations haven’t explicitly addressed yet.

	1. Ethical Frameworks Using AI: guidelines and principles designed to ensure AI systems operate responsibly, fairly, and without harmful biases. Making sure someone is answerable if things go wrong.

	2. Legal Frameworks Using AI: Laws and regulations that govern how AI should be created, deployed, and monitored. Deciding who is responsible when AI systems cause errors or harm.



Problems created by AI in the Financial Industry

1. Managing Machine Learning Biases: This bias comes from the training data which leads to unfair treatment of customers from a certain demographics. AI can be biased based one data coming from card usage because card data are used in predictions like credit analysis, default risk and creditworthiness.
	Bias in this context doesn’t mean the AI is simply or outright “wrong” or “off”—it means the AI is consistently skewed in a certain direction, often favoring one group or outcome over another. 

2. Abusing Data Coming from Card Usage: AI systems could deny loans based on questionable indicators (like an IP address) or misuse personal transaction data to make biased decisions.

	1. Denied Loans Based on Demographics: Ex; A user applying for a credit card from a Las Vegas IP might be unfairly rejected if the AI associates that location with high default risk.

	2. Fraud Prediction or Undesirable Outcomes:AI systems designed to flag fraud, instead generate harmful results, like wrongly denying legitimate transactions or loans.


3. Lack of Transparency: Many AI models operate as “black boxes,” and it’s unclear which data points influence decisions or how those decisions are made. Example: A customer denied a loan might never learn the specific factors (e.g., spending habits, type of employment) that led to the denial.

4. Data Breaches: Large-scale AI systems hold sensitive information; if breached, massive amounts of personal and financial data could be exposed.
Example: A targeted hack on an AI-driven credit card application service could leak thousands of social security numbers and account details. 

5. Data Security and Confidentiality are at stake: With AI handling so much personal data, ensuring robust protection against unauthorized access becomes increasingly difficult.
Example: Even routine data transfers for model training could expose confidential client details if not properly encrypted.
  



